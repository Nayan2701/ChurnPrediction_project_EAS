{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current Directory: /Users/nayanpaliwal/Desktop/Eas_final_project/housing_app_fall25/notebooks\n",
            "✓ Found housing_pipeline.py at: /Users/nayanpaliwal/Desktop/Eas_final_project/housing_app_fall25/housing_pipeline.py\n",
            "✓ Added parent directory to path.\n",
            "SUCCESS: Module imported correctly!\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "# 1. Print where we are currently running\n",
        "current_dir = os.getcwd()\n",
        "print(f\"Current Directory: {current_dir}\")\n",
        "\n",
        "# 2. Check if the file is in the parent directory (one folder up)\n",
        "parent_dir = os.path.abspath(os.path.join(current_dir, '..'))\n",
        "file_path = os.path.join(parent_dir, 'housing_pipeline.py')\n",
        "\n",
        "if os.path.exists(file_path):\n",
        "    print(f\"✓ Found housing_pipeline.py at: {file_path}\")\n",
        "    # Add the parent directory to Python's path\n",
        "    if parent_dir not in sys.path:\n",
        "        sys.path.insert(0, parent_dir)\n",
        "        print(\"✓ Added parent directory to path.\")\n",
        "else:\n",
        "    # 3. Fallback: Check if we are already in the root folder\n",
        "    local_path = os.path.join(current_dir, 'housing_pipeline.py')\n",
        "    if os.path.exists(local_path):\n",
        "        print(f\"✓ Found housing_pipeline.py in current folder.\")\n",
        "        if current_dir not in sys.path:\n",
        "            sys.path.insert(0, current_dir)\n",
        "    else:\n",
        "        print(\"❌ CRITICAL ERROR: Could not find 'housing_pipeline.py'.\")\n",
        "        print(\"Please make sure the file exists in the project root folder.\")\n",
        "\n",
        "# 4. Now try to import\n",
        "try:\n",
        "    import housing_pipeline\n",
        "    from housing_pipeline import build_preprocessing, make_estimator_for_name\n",
        "    print(\"SUCCESS: Module imported correctly!\")\n",
        "except ImportError as e:\n",
        "    print(f\"Import failed: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmSRGJ9R1kTi",
        "outputId": "20c1a54a-81c4-45e5-8bd0-f8a08cea6d90"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[32m      2\u001b[39m drive.mount(\u001b[33m'\u001b[39m\u001b[33m/content/drive\u001b[39m\u001b[33m'\u001b[39m)\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfaWlb492CvZ",
        "outputId": "74e2ca27-7257-41cc-e46a-14905665a684"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/Colab Notebooks/housing_fall2025\n"
          ]
        }
      ],
      "source": [
        "base_folder = \"/content/drive/MyDrive/Colab Notebooks/housing_fall2025\"\n",
        "%cd \"{base_folder}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7rUZ8BQ2kYL",
        "outputId": "22263b6f-bdb4-4ab5-c885-3bac96812bca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building Normalized Database...\n",
            "✓ Database created at ../data/churn.db\n"
          ]
        }
      ],
      "source": [
        "# notebooks/01_create_database.ipynb\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Define paths\n",
        "\n",
        "DATA_DIR = Path(\"../data\")\n",
        "DB_PATH = DATA_DIR / \"churn.db\"\n",
        "CSV_PATH = DATA_DIR / \"Churn_Modelling.csv\"\n",
        "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 1. GET DATA (If you don't have the CSV, this creates dummy data to ensure it runs)\n",
        "if not CSV_PATH.exists():\n",
        "    print(\"Creating dummy Churn dataset...\")\n",
        "    df = pd.DataFrame({\n",
        "        'CustomerId': range(100),\n",
        "        'CreditScore': np.random.randint(350, 850, 100),\n",
        "        'Geography': np.random.choice(['France', 'Spain', 'Germany'], 100),\n",
        "        'Gender': np.random.choice(['Female', 'Male'], 100),\n",
        "        'Age': np.random.randint(18, 90, 100),\n",
        "        'Tenure': np.random.randint(0, 10, 100),\n",
        "        'Balance': np.random.uniform(0, 200000, 100),\n",
        "        'NumOfProducts': np.random.choice([1, 2, 3, 4], 100),\n",
        "        'HasCrCard': np.random.choice([0, 1], 100),\n",
        "        'IsActiveMember': np.random.choice([0, 1], 100),\n",
        "        'EstimatedSalary': np.random.uniform(20000, 150000, 100),\n",
        "        'Exited': np.random.choice([0, 1], 100)\n",
        "    })\n",
        "    df.to_csv(CSV_PATH, index=False)\n",
        "else:\n",
        "    df = pd.read_csv(CSV_PATH)\n",
        "\n",
        "# 2. NORMALIZE & SAVE TO DB\n",
        "print(\"Building Normalized Database...\")\n",
        "if DB_PATH.exists(): os.remove(DB_PATH)\n",
        "conn = sqlite3.connect(DB_PATH)\n",
        "cur = conn.cursor()\n",
        "\n",
        "# Create Tables\n",
        "cur.executescript(\"\"\"\n",
        "    CREATE TABLE geography (GeographyID INTEGER PRIMARY KEY, Name TEXT UNIQUE);\n",
        "    CREATE TABLE gender (GenderID INTEGER PRIMARY KEY, Name TEXT UNIQUE);\n",
        "    CREATE TABLE customer (\n",
        "        CustomerId INTEGER PRIMARY KEY, CreditScore INTEGER, GeographyID INTEGER, GenderID INTEGER,\n",
        "        Age INTEGER, Tenure INTEGER, Balance REAL, NumOfProducts INTEGER, HasCrCard INTEGER,\n",
        "        IsActiveMember INTEGER, EstimatedSalary REAL, Exited INTEGER,\n",
        "        FOREIGN KEY(GeographyID) REFERENCES geography(GeographyID),\n",
        "        FOREIGN KEY(GenderID) REFERENCES gender(GenderID)\n",
        "    );\n",
        "\"\"\")\n",
        "\n",
        "# Insert Data\n",
        "geo_dim = df[['Geography']].drop_duplicates().reset_index(drop=True)\n",
        "geo_dim['ID'] = geo_dim.index + 1\n",
        "gen_dim = df[['Gender']].drop_duplicates().reset_index(drop=True)\n",
        "gen_dim['ID'] = gen_dim.index + 1\n",
        "\n",
        "cur.executemany(\"INSERT INTO geography VALUES (?, ?)\", list(zip(geo_dim['ID'], geo_dim['Geography'])))\n",
        "cur.executemany(\"INSERT INTO gender VALUES (?, ?)\", list(zip(gen_dim['ID'], gen_dim['Gender'])))\n",
        "\n",
        "df = df.merge(geo_dim, on='Geography').merge(gen_dim, on='Gender')\n",
        "cols = ['CustomerId', 'CreditScore', 'ID_x', 'ID_y', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary', 'Exited']\n",
        "cur.executemany(f\"INSERT INTO customer VALUES ({','.join(['?']*12)})\", df[cols].values.tolist())\n",
        "\n",
        "conn.commit()\n",
        "conn.close()\n",
        "print(f\"✓ Database created at {DB_PATH}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== DEBUGGING INFO ===\n",
            "1. File Location: /Users/nayanpaliwal/Desktop/Eas_final_project/housing_app_fall25/housing_pipeline.py\n",
            "2. Last Modified: 1766080779.7209566\n",
            "\n",
            "3. Checking code inside 'make_estimator_for_name':\n",
            "def make_estimator_for_name(name: str):\n",
            "    \"\"\"\n",
            "    Given a model name, return an unconfigured estimator instance.\n",
            "    Used in PCA variants and (optionally) elsewhere.\n",
            "    \"\"\"\n",
            "    if name == \"ridge\":\n",
            "        return Ridge()\n",
            "    elif name == \"histgradientboosting\":\n",
            "        return HistGradientBoostingRegressor(random_state=42)\n",
            "    elif name == \"xgboost\":\n",
            "        return XGBRegressor(\n",
            "            objective=\"reg:squarederror\",\n",
            "            random_state=42,\n",
            "            n_estimators=300,\n",
            "            learning_rate=0.1,\n",
            "            max_depth=6,\n",
            "            subsample=0.8,\n",
            "            colsample_bytree=0.8,\n",
            "            tree_method=\"hist\",\n",
            "            n_jobs=-1,\n",
            "        )\n",
            "    elif name == \"lightgbm\":\n",
            "        return LGBMRegressor(\n",
            "            random_state=42,\n",
            "            n_estimators=300,\n",
            "            learning_rate=0.05,\n",
            "            num_leaves=31,\n",
            "            subsample=0.8,\n",
            "            colsample_bytree=0.8,\n",
            "            n_jobs=-1,\n",
            "        )\n",
            "    else:\n",
            "        raise ValueError(f\"Unknown model name: {name}\")\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import housing_pipeline\n",
        "import inspect\n",
        "import os\n",
        "\n",
        "print(\"=== DEBUGGING INFO ===\")\n",
        "print(f\"1. File Location: {housing_pipeline.__file__}\")\n",
        "print(f\"2. Last Modified: {os.path.getmtime(housing_pipeline.__file__)}\")\n",
        "\n",
        "print(\"\\n3. Checking code inside 'make_estimator_for_name':\")\n",
        "try:\n",
        "    print(inspect.getsource(housing_pipeline.make_estimator_for_name))\n",
        "except Exception as e:\n",
        "    print(f\"Could not read source: {e}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "my-new-kernel",
      "language": "python",
      "name": "my-new-kernel"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
